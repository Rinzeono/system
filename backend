from fastapi import FastAPI, WebSocket, WebSocketDisconnect, UploadFile, Request, File
from fastapi.middleware.cors import CORSMiddleware
from starlette.websockets import WebSocketState
import uvicorn
import tempfile
import json
import os
import requests
import asyncio
import websockets
import subprocess

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logs = {
    "taro_input": [0],
    "jiro_input": [0],
    "taro_speech": [{"transcript": "", "length": 0}],
    "jiro_speech": [{"transcript": "", "length": 0}],
    "transcript": ""
}

class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            if connection.application_state == WebSocketState.CONNECTED:
                await connection.send_json(message)

manager = ConnectionManager()

@app.websocket("/ws/data")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            await websocket.receive_text()
            await websocket.send_json(logs)
    except WebSocketDisconnect:
        manager.disconnect(websocket)

@app.post("/stream/input")
async def stream_input(request: Request):
    speaker = request.query_params.get("speaker")
    length = request.query_params.get("length")
    if speaker not in ["taro", "jiro"]:
        return {"status": "error", "msg": "invalid speaker"}
    try:
        length = int(length)
    except Exception:
        length = 0
    logs[f"{speaker}_input"].append(length)
    await manager.broadcast(logs)
    return {"status": "ok"}

@app.post("/stream/audio")
async def stream_audio(speaker: str, file: UploadFile = File(...)):
    audio_bytes = await file.read()
    with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as f:
        f.write(audio_bytes)
        webm_path = f.name
    wav_path = webm_path.replace(".webm", ".wav")
    try:
        subprocess.run([
            "ffmpeg", "-y", "-i", webm_path,
            "-ar", "16000", "-ac", "1", "-f", "wav", wav_path
        ], check=True)
    except subprocess.CalledProcessError as e:
        print("ffmpeg変換失敗:", e)
        return {"status": "error", "msg": "ffmpeg変換失敗。webmファイルが不正な可能性があります。"}
    if not os.path.exists(wav_path):
        return {"status": "error", "msg": "wavファイルが生成されませんでした。"}
    with open(wav_path, "rb") as f:
        wav_bytes = f.read()
    print("wav_bytes[:16] =", wav_bytes[:16])
    transcript, length = await transcribe_audio_stream([wav_bytes])
    logs[f"{speaker}_speech"].append({"transcript": transcript, "length": length})
    logs["transcript"] = transcript
    await manager.broadcast(logs)
    return {"transcript": transcript, "length": length}

async def transcribe_audio_stream(audio_chunks):
    uri = "ws://localhost:8000/asr?language=ja"
    transcript = ""
    async with websockets.connect(uri) as websocket:
        # WhisperLiveKitは接続後すぐacceptされる仕様
        for chunk in audio_chunks:
            await websocket.send(chunk)  # chunkはbytes型
        # 結果を受信（WhisperLiveKitは複数回返す場合あり）
        while True:
            result = await websocket.recv()
            try:
                data = json.loads(result)
                if "text" in data:
                    transcript += data["text"]
                if data.get("type") == "ready_to_stop":
                    break
            except Exception:
                transcript += result
    return transcript, len(transcript)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001, log_level="info")
